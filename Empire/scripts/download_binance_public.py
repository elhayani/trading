#!/usr/bin/env python3
"""
Script pour tÃ©lÃ©charger l'historique des 415 actifs de Binance Futures (mode public)
PÃ©riode: Semaine derniÃ¨re (7 jours)
Format: CSV avec OHLCV data
"""

import ccxt
import pandas as pd
import os
import time
from datetime import datetime, timedelta
import json
import logging

# Configuration
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class BinancePublicDownloader:
    def __init__(self):
        """Initialiser le client Binance Futures (mode public)"""
        self.exchange = ccxt.binance({
            'sandbox': False,  # Production
            'enableRateLimit': True,
            'timeout': 30000,
            'options': {
                'defaultType': 'future',  # Forcer Futures
            }
        })
        
    def get_all_futures_symbols(self):
        """RÃ©cupÃ©rer tous les symboles disponibles sur Binance Futures"""
        try:
            markets = self.exchange.load_markets()
            futures_symbols = []
            
            for symbol, market in markets.items():
                if market.get('type') == 'future' and market.get('active', True):
                    # Filtrer uniquement les paires USDT
                    if symbol.endswith('/USDT'):
                        futures_symbols.append(symbol)
            
            logger.info(f"âœ… TrouvÃ© {len(futures_symbols)} actifs Futures USDT")
            return sorted(futures_symbols)
            
        except Exception as e:
            logger.error(f"âŒ Erreur rÃ©cupÃ©ration symboles: {e}")
            return []
    
    def download_symbol_history(self, symbol, days=7):
        """TÃ©lÃ©charger l'historique pour un symbole"""
        try:
            # Calculer les dates
            end_time = datetime.now()
            start_time = end_time - timedelta(days=days)
            
            # Convertir en timestamps
            since = self.exchange.parse8601(start_time.isoformat())
            
            logger.info(f"ğŸ“¥ TÃ©lÃ©chargement {symbol} ({days} jours)...")
            
            # RÃ©cupÃ©rer les donnÃ©es OHLCV
            ohlcv = self.exchange.fetch_ohlcv(
                symbol, 
                timeframe='1h',  # 1 heure pour avoir assez de donnÃ©es
                since=since,
                limit=1000  # Max par requÃªte
            )
            
            if not ohlcv:
                logger.warning(f"âš ï¸  Pas de donnÃ©es pour {symbol}")
                return None
            
            # Convertir en DataFrame
            df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            df['symbol'] = symbol
            
            # Calculer des indicateurs de base
            df['range'] = df['high'] - df['low']
            df['change'] = ((df['close'] - df['open']) / df['open'] * 100).round(2)
            df['volume_usd'] = (df['volume'] * df['close']).round(2)
            
            # Statistiques basiques
            stats = {
                'symbol': symbol,
                'total_candles': len(df),
                'avg_volume': df['volume'].mean(),
                'avg_volume_usd': df['volume_usd'].mean(),
                'volatility': df['change'].std(),
                'max_change': df['change'].max(),
                'min_change': df['change'].min(),
                'price_range': df['high'].max() - df['low'].min(),
                'start_price': df['close'].iloc[0],
                'end_price': df['close'].iloc[-1],
                'total_change': ((df['close'].iloc[-1] - df['close'].iloc[0]) / df['close'].iloc[0] * 100).round(2)
            }
            
            logger.info(f"âœ… {symbol}: {len(df)} candles | Change: {stats['total_change']:.2f}%")
            return df, stats
            
        except Exception as e:
            logger.error(f"âŒ Erreur {symbol}: {e}")
            return None, None
    
    def download_all_history(self, days=7, max_symbols=415):
        """TÃ©lÃ©charger l'historique pour tous les symboles"""
        # CrÃ©er le rÃ©pertoire de sortie
        output_dir = f"binance_history_{datetime.now().strftime('%Y%m%d')}"
        os.makedirs(output_dir, exist_ok=True)
        
        # RÃ©cupÃ©rer tous les symboles
        symbols = self.get_all_futures_symbols()
        
        # Limiter si nÃ©cessaire
        if len(symbols) > max_symbols:
            symbols = symbols[:max_symbols]
            logger.info(f"ğŸ“Š LimitÃ© Ã  {max_symbols} symboles")
        
        # TÃ©lÃ©charger pour chaque symbole
        all_data = []
        all_stats = []
        failed_symbols = []
        
        logger.info(f"ğŸš€ DÃ©marrage du tÃ©lÃ©chargement de {len(symbols)} symboles...")
        
        for i, symbol in enumerate(symbols, 1):
            logger.info(f"ğŸ”„ [{i}/{len(symbols)}] {symbol}")
            
            df, stats = self.download_symbol_history(symbol, days)
            if df is not None:
                all_data.append(df)
                all_stats.append(stats)
                
                # Sauvegarder individuellement
                filename = f"{output_dir}/{symbol.replace('/', '_')}.csv"
                df.to_csv(filename, index=False)
                
            else:
                failed_symbols.append(symbol)
            
            # Rate limiting
            time.sleep(0.2)  # 200ms entre les requÃªtes
            
            # Sauvegarde intermÃ©diaire tous les 50 symboles
            if i % 50 == 0:
                logger.info(f"ğŸ’¾ Sauvegarde intermÃ©diaire ({i} symboles)")
                self.save_combined_data(all_data, output_dir, f"intermediate_{i}")
        
        # Combiner toutes les donnÃ©es
        if all_data:
            combined_df = pd.concat(all_data, ignore_index=True)
            
            # Sauvegarder le fichier combinÃ©
            combined_file = f"{output_dir}/all_futures_history_{days}days.csv"
            combined_df.to_csv(combined_file, index=False)
            
            # CrÃ©er un rÃ©sumÃ© dÃ©taillÃ©
            summary = {
                'download_date': datetime.now().isoformat(),
                'period_days': days,
                'total_symbols': len(symbols),
                'successful_downloads': len(all_data),
                'failed_downloads': len(failed_symbols),
                'total_candles': len(combined_df),
                'date_range': {
                    'start': combined_df['timestamp'].min().isoformat(),
                    'end': combined_df['timestamp'].max().isoformat()
                },
                'failed_symbols': failed_symbols,
                'top_performers': sorted(all_stats, key=lambda x: x['total_change'], reverse=True)[:10],
                'worst_performers': sorted(all_stats, key=lambda x: x['total_change'])[:10],
                'most_volatile': sorted(all_stats, key=lambda x: x['volatility'], reverse=True)[:10],
                'highest_volume': sorted(all_stats, key=lambda x: x['avg_volume_usd'], reverse=True)[:10]
            }
            
            # Sauvegarder le rÃ©sumÃ©
            with open(f"{output_dir}/summary.json", 'w') as f:
                json.dump(summary, f, indent=2)
            
            # CrÃ©er un CSV des statistiques
            stats_df = pd.DataFrame(all_stats)
            stats_df.to_csv(f"{output_dir}/symbols_stats.csv", index=False)
            
            # Afficher le rÃ©sumÃ©
            logger.info("ğŸ‰ TÃ‰LÃ‰CHARGEMENT TERMINÃ‰!")
            logger.info(f"ğŸ“Š SuccÃ¨s: {len(all_data)}/{len(symbols)} symboles")
            logger.info(f"ğŸ“ˆ Total candles: {len(combined_df):,}")
            logger.info(f"ğŸ“ RÃ©pertoire: {output_dir}")
            logger.info(f"ğŸ”¥ Top performer: {summary['top_performers'][0]['symbol']} (+{summary['top_performers'][0]['total_change']:.2f}%)")
            logger.info(f"ğŸ’€ Worst performer: {summary['worst_performers'][0]['symbol']} ({summary['worst_performers'][0]['total_change']:.2f}%)")
            
            return combined_df, summary
        else:
            logger.error("âŒ Aucune donnÃ©e tÃ©lÃ©chargÃ©e")
            return None, None
    
    def save_combined_data(self, data_list, output_dir, filename):
        """Sauvegarder les donnÃ©es combinÃ©es"""
        if data_list:
            combined_df = pd.concat(data_list, ignore_index=True)
            combined_df.to_csv(f"{output_dir}/{filename}.csv", index=False)

def main():
    """Fonction principale"""
    logger.info("ğŸš€ DÃ©marrage du tÃ©lÃ©chargement de l'historique Binance Futures (mode public)")
    
    # CrÃ©er le downloader
    downloader = BinancePublicDownloader()
    
    # TÃ©lÃ©charger l'historique (7 jours = semaine derniÃ¨re)
    df, summary = downloader.download_all_history(days=7, max_symbols=415)
    
    if df is not None:
        logger.info("\nâœ… TÃ‰LÃ‰CHARGEMENT TERMINÃ‰ AVEC SUCCÃˆS!")
        logger.info(f"ğŸ“Š Fichiers disponibles dans le rÃ©pertoire crÃ©Ã©")
    else:
        logger.error("âŒ Ã‰chec du tÃ©lÃ©chargement")

if __name__ == "__main__":
    main()
