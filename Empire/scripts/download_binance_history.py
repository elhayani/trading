#!/usr/bin/env python3
"""
Script pour tÃ©lÃ©charger l'historique des 415 actifs de Binance Futures
PÃ©riode: Semaine derniÃ¨re (7 jours)
Format: CSV avec OHLCV data
"""

import ccxt
import pandas as pd
import os
import time
from datetime import datetime, timedelta
import json
import logging

# Configuration
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class BinanceHistoryDownloader:
    def __init__(self):
        """Initialiser le client Binance Futures"""
        self.exchange = ccxt.binance({
            'apiKey': os.getenv('BINANCE_API_KEY', ''),
            'secret': os.getenv('BINANCE_SECRET', ''),
            'sandbox': False,  # Production
            'enableRateLimit': True,
            'timeout': 30000,
        })
        
        # Forcer le mode Futures
        self.exchange.set_sandbox_mode(False)
        self.exchange.options['defaultType'] = 'future'
        
    def get_all_futures_symbols(self):
        """RÃ©cupÃ©rer tous les symboles disponibles sur Binance Futures"""
        try:
            markets = self.exchange.load_markets()
            futures_symbols = []
            
            for symbol, market in markets.items():
                if market.get('type') == 'future' and market.get('active', True):
                    # Filtrer uniquement les paires USDT
                    if symbol.endswith('/USDT'):
                        futures_symbols.append(symbol)
            
            logger.info(f"âœ… TrouvÃ© {len(futures_symbols)} actifs Futures USDT")
            return sorted(futures_symbols)
            
        except Exception as e:
            logger.error(f"âŒ Erreur rÃ©cupÃ©ration symboles: {e}")
            return []
    
    def download_symbol_history(self, symbol, days=7):
        """TÃ©lÃ©charger l'historique pour un symbole"""
        try:
            # Calculer les dates
            end_time = datetime.now()
            start_time = end_time - timedelta(days=days)
            
            # Convertir en timestamps
            since = self.exchange.parse8601(start_time.isoformat())
            
            logger.info(f"ğŸ“¥ TÃ©lÃ©chargement {symbol} ({days} jours)...")
            
            # RÃ©cupÃ©rer les donnÃ©es OHLCV
            ohlcv = self.exchange.fetch_ohlcv(
                symbol, 
                timeframe='1h',  # 1 heure pour avoir assez de donnÃ©es
                since=since,
                limit=1000  # Max par requÃªte
            )
            
            if not ohlcv:
                logger.warning(f"âš ï¸  Pas de donnÃ©es pour {symbol}")
                return None
            
            # Convertir en DataFrame
            df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            df['symbol'] = symbol
            
            # Calculer des indicateurs de base
            df['range'] = df['high'] - df['low']
            df['change'] = ((df['close'] - df['open']) / df['open'] * 100).round(2)
            df['volume_usd'] = (df['volume'] * df['close']).round(2)
            
            logger.info(f"âœ… {symbol}: {len(df)} candles tÃ©lÃ©chargÃ©es")
            return df
            
        except Exception as e:
            logger.error(f"âŒ Erreur {symbol}: {e}")
            return None
    
    def download_all_history(self, days=7, max_symbols=415):
        """TÃ©lÃ©charger l'historique pour tous les symboles"""
        # CrÃ©er le rÃ©pertoire de sortie
        output_dir = f"binance_history_{datetime.now().strftime('%Y%m%d')}"
        os.makedirs(output_dir, exist_ok=True)
        
        # RÃ©cupÃ©rer tous les symboles
        symbols = self.get_all_futures_symbols()
        
        # Limiter si nÃ©cessaire
        if len(symbols) > max_symbols:
            symbols = symbols[:max_symbols]
            logger.info(f"ğŸ“Š LimitÃ© Ã  {max_symbols} symboles")
        
        # TÃ©lÃ©charger pour chaque symbole
        all_data = []
        failed_symbols = []
        
        for i, symbol in enumerate(symbols, 1):
            logger.info(f"ğŸ”„ Progression: {i}/{len(symbols)} - {symbol}")
            
            df = self.download_symbol_history(symbol, days)
            if df is not None:
                all_data.append(df)
                
                # Sauvegarder individuellement
                filename = f"{output_dir}/{symbol.replace('/', '_')}.csv"
                df.to_csv(filename, index=False)
                
            else:
                failed_symbols.append(symbol)
            
            # Rate limiting
            time.sleep(0.1)
            
            # Sauvegarde intermÃ©diaire tous les 50 symboles
            if i % 50 == 0:
                logger.info(f"ğŸ’¾ Sauvegarde intermÃ©diaire ({i} symboles)")
                self.save_combined_data(all_data, output_dir, f"intermediate_{i}")
        
        # Combiner toutes les donnÃ©es
        if all_data:
            combined_df = pd.concat(all_data, ignore_index=True)
            
            # Sauvegarder le fichier combinÃ©
            combined_file = f"{output_dir}/all_futures_history_{days}days.csv"
            combined_df.to_csv(combined_file, index=False)
            
            # CrÃ©er un rÃ©sumÃ©
            summary = {
                'download_date': datetime.now().isoformat(),
                'period_days': days,
                'total_symbols': len(symbols),
                'successful_downloads': len(all_data),
                'failed_downloads': len(failed_symbols),
                'total_candles': len(combined_df),
                'date_range': {
                    'start': combined_df['timestamp'].min().isoformat(),
                    'end': combined_df['timestamp'].max().isoformat()
                },
                'failed_symbols': failed_symbols
            }
            
            with open(f"{output_dir}/summary.json", 'w') as f:
                json.dump(summary, f, indent=2)
            
            logger.info(f"ğŸ‰ TerminÃ©! {len(all_data)} symboles tÃ©lÃ©chargÃ©s")
            logger.info(f"ğŸ“ Fichiers sauvegardÃ©s dans: {output_dir}")
            logger.info(f"ğŸ“Š Total candles: {len(combined_df)}")
            logger.info(f"âŒ Ã‰checs: {len(failed_symbols)} symboles")
            
            return combined_df, summary
        else:
            logger.error("âŒ Aucune donnÃ©e tÃ©lÃ©chargÃ©e")
            return None, None
    
    def save_combined_data(self, data_list, output_dir, filename):
        """Sauvegarder les donnÃ©es combinÃ©es"""
        if data_list:
            combined_df = pd.concat(data_list, ignore_index=True)
            combined_df.to_csv(f"{output_dir}/{filename}.csv", index=False)

def main():
    """Fonction principale"""
    logger.info("ğŸš€ DÃ©marrage du tÃ©lÃ©chargement de l'historique Binance Futures")
    
    # VÃ©rifier les variables d'environnement
    if not os.getenv('BINANCE_API_KEY'):
        logger.error("âŒ BINANCE_API_KEY non dÃ©fini")
        return
    
    if not os.getenv('BINANCE_SECRET'):
        logger.error("âŒ BINANCE_SECRET non dÃ©fini")
        return
    
    # CrÃ©er le downloader
    downloader = BinanceHistoryDownloader()
    
    # TÃ©lÃ©charger l'historique (7 jours = semaine derniÃ¨re)
    df, summary = downloader.download_all_history(days=7, max_symbols=415)
    
    if df is not None:
        logger.info("âœ… TÃ©lÃ©chargement terminÃ© avec succÃ¨s!")
        logger.info(f"ğŸ“Š RÃ©sumÃ©: {summary['successful_downloads']}/{summary['total_symbols']} symboles")
    else:
        logger.error("âŒ Ã‰chec du tÃ©lÃ©chargement")

if __name__ == "__main__":
    main()
